// src/components/VoiceRecorder.jsx
import { useState, useEffect, useRef } from 'react';
import apiClient from '../api/axios';

import VolumeVisualizer from './VolumeVisualizer'; // å¼•å…¥æ–°çš„éŸ³é‡å¯è§†åŒ–ç»„ä»¶

// å¼‚æ­¥ä¸‹è½½ RecordRTC
const getRecordRTC = async () => {
  try {
    const RecordRTC = (await import('recordrtc')).default;
    return RecordRTC;
  } catch (err) {
    console.error('RecordRTC åŠ è½½å¤±è´¥:', err);
    throw new Error('RecordRTC åŠ è½½å¤±è´¥ï¼š' + err.message);
  }
};

/**
 * VoiceRecorder ç»„ä»¶
 * æä¾›è¯­éŸ³å½•åˆ¶ã€æ’­æ”¾ã€è½¬æ–‡å­—åŠŸèƒ½
 * @param {Function} onTranscribeComplete - è½¬æ–‡å­—å®Œæˆåçš„å›è°ƒ (text) => void
 * @param {string} relatedId - å…³è”çš„çŸ¥è¯†ç‚¹ IDï¼ˆç”¨äºä¸Šä¼ ï¼‰
 * @param {string} transcribedText - å—æ§æ–‡æœ¬æ¡†å†…å®¹ï¼ˆçˆ¶ç»„ä»¶ç®¡ç†ï¼‰
 * @param {Function} onTextChange - æ–‡æœ¬æ¡†å˜åŒ–å›è°ƒ
 */
function VoiceRecorder({ onTranscribeComplete, relatedId, transcribedText, onTextChange }) {
  const [status, setStatus] = useState('idle'); // idle, recording, paused
  const [seconds, setSeconds] = useState(0);
  const [isUploading, setIsUploading] = useState(false);
  const [volume, setVolume] = useState(0);
  const [mediaBlobUrl, setMediaBlobUrl] = useState('');
  
  // è½¬å½•æ–¹å¼ä¸å¤±è´¥è®¡æ•°
  const [transcriptionMethod, setTranscriptionMethod] = useState(() => {
    const saved = typeof window !== 'undefined' ? localStorage.getItem('transcriptionMethod') : null;
    const enableWhisper = import.meta?.env?.VITE_ENABLE_WHISPER !== 'false';
    return saved || (enableWhisper ? 'whisper' : 'baidu');
  });
  const [failureCount, setFailureCount] = useState(0);

  const timerRef = useRef(null);
  const recorderRef = useRef(null);
  const volumeRef = useRef(0);
  const audioCtxRef = useRef(null);
  const analyserRef = useRef(null);
  const rafRef = useRef(null);
  const streamRef = useRef(null);

  // è®¡æ—¶å™¨
  useEffect(() => {
    if (status === 'recording') {
      if (!timerRef.current) {
        timerRef.current = setInterval(() => setSeconds((s) => s + 1), 1000);
      }
    } else {
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    }
    return () => {
      if (timerRef.current) clearInterval(timerRef.current);
    };
  }, [status]);

  // è®¾ç½®éŸ³é‡ç›‘å¬ï¼ˆä½¿ç”¨å·²æœ‰çš„ streamï¼‰
  const setupVolumeMeter = (stream) => {
    try {
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      audioCtxRef.current = audioCtx;
      const source = audioCtx.createMediaStreamSource(stream);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 512;
      analyserRef.current = analyser;
      source.connect(analyser);

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      const tick = () => {
        analyser.getByteTimeDomainData(dataArray);
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          const v = (dataArray[i] - 128) / 128;
          sum += v * v;
        }
        const rms = Math.sqrt(sum / dataArray.length);
        const level = Math.min(1, rms * 3);
        volumeRef.current = level;
        setVolume(level);
        rafRef.current = requestAnimationFrame(tick);
      };
      tick();
    } catch (err) {
      console.warn('éŸ³é‡ç›‘å¬åˆå§‹åŒ–å¤±è´¥:', err?.message);
    }
  };

  const teardownVolumeMeter = () => {
    if (rafRef.current) cancelAnimationFrame(rafRef.current);
    if (audioCtxRef.current) {
      audioCtxRef.current.close();
      audioCtxRef.current = null;
    }
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((t) => t.stop());
      streamRef.current = null;
    }
    analyserRef.current = null;
    setVolume(0);
  };

  // ä¸Šä¼  Blob è¿›è¡Œè¯­éŸ³è¯†åˆ«
  const uploadBlob = async (audioBlob) => {
    setIsUploading(true);
    if (onTextChange) onTextChange(''); // æ¸…ç©ºçˆ¶ç»„ä»¶æ–‡æœ¬
    try {
      const mime = audioBlob.type || 'audio/wav';
      const audioFile = new File([audioBlob], `voice-record-${relatedId}.wav`, { type: mime });

      const formData = new FormData();
      formData.append('audio', audioFile);
      formData.append('knowledgePointId', relatedId);
      formData.append('durationSeconds', String(seconds));
      formData.append('mimeType', mime);

      const endpoint = transcriptionMethod === 'whisper' ? '/audio/transcribe-local' : '/audio/transcribe';
      console.info(`[VoiceRecorder] ä½¿ç”¨ ${transcriptionMethod === 'whisper' ? 'Whisper' : 'ç™¾åº¦API'} è¿›è¡Œè½¬å½• -> ${endpoint}`);
      const response = await apiClient.post(endpoint, formData, {
        headers: { 'Content-Type': 'multipart/form-data' },
      });

      const result =
        response.data?.result ||
        response.data?.text ||
        response.data?.transcription ||
        response.data?.DisplayText ||
        response.data?.results?.[0]?.alternatives?.[0]?.transcript ||
        '';
      const msg = response.data?.msg || response.data?.message || '';
      const text = result || msg || 'è½¬å½•ç»“æœä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•ã€‚';
      if (onTextChange) onTextChange(text); // æ›´æ–°çˆ¶ç»„ä»¶æ–‡æœ¬

      // æˆåŠŸåˆ™é‡ç½® Whisper å¤±è´¥è®¡æ•°
      if (transcriptionMethod === 'whisper' && failureCount !== 0) {
        setFailureCount(0);
      }

      if (onTranscribeComplete) {
        onTranscribeComplete(text);
      }
    } catch (error) {
      const status = error?.response?.status;
      const suggestion = error?.response?.data?.suggestion || '';
      const errorMsg =
        error?.response?.data?.msg ||
        error?.response?.data?.error ||
        error?.message ||
        'è½¬å½•å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚';

      // Whisperä¸‹çš„è‡ªåŠ¨é™çº§é€»è¾‘
      if (transcriptionMethod === 'whisper' && (status === 503 || status === 504)) {
        const newCount = failureCount + 1;
        setFailureCount(newCount);
        if (newCount >= 3) {
          console.warn('Whisper è¿ç»­å¤±è´¥ 3 æ¬¡ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ç™¾åº¦ API');
          setTranscriptionMethod('baidu');
          if (typeof window !== 'undefined') localStorage.setItem('transcriptionMethod', 'baidu');
          setFailureCount(0);
        }
      }

      const text = `è½¬å½•å¤±è´¥: ${errorMsg}${suggestion ? `ï¼Œå»ºè®®ï¼š${suggestion}` : ''}`;
      if (onTextChange) onTextChange(text); // æ›´æ–°çˆ¶ç»„ä»¶é”™è¯¯æ–‡æœ¬
      if (onTranscribeComplete) {
        onTranscribeComplete(text);
      }
    } finally {
      setIsUploading(false);
    }
  };

  const handleStart = async () => {
    setSeconds(0);
    try {
      // æ­¤æ—¶åŠ¨æ€åŠ è½½ RecordRTC
      const RecordRTC = await getRecordRTC();
      if (!RecordRTC) {
        throw new Error('RecordRTC æ¨¡å—æš‘æœªåŠ è½½');
      }

      // å”¯ä¸€ä¸€æ¬¡ getUserMedia è°ƒç”¨
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
      });
      streamRef.current = stream;
      
      // é…ç½®éŸ³é‡ç›‘å¬ï¼ˆä½¿ç”¨ä¸ºè·å–çš„ streamï¼‰
      setupVolumeMeter(stream);
      
      const recorder = new RecordRTC(stream, {
        type: 'audio',
        mimeType: 'audio/wav',
        recorderType: RecordRTC.StereoAudioRecorder,
        numberOfAudioChannels: 1,
      });
      recorderRef.current = recorder;
      recorder.startRecording();
      setStatus('recording');
    } catch (err) {
      console.error('æ— æ³•å¼€å§‹å½•éŸ³:', err);
      teardownVolumeMeter();
    }
  };

  const handleStop = () => {
    teardownVolumeMeter();
    if (!recorderRef.current) return;
    const recorder = recorderRef.current;
    recorder.stopRecording(async () => {
      try {
        const blob = recorder.getBlob();
        const url = URL.createObjectURL(blob);
        setMediaBlobUrl(url);
        setStatus('idle');
        await uploadBlob(blob);
      } catch (err) {
        console.error('åœæ­¢å½•éŸ³å¤±è´¥:', err);
      } finally {
        if (streamRef.current) {
          streamRef.current.getTracks().forEach((t) => t.stop());
          streamRef.current = null;
        }
        recorderRef.current = null;
      }
    });
  };

  const handlePause = () => {
    if (!recorderRef.current) return;
    try {
      recorderRef.current.pauseRecording();
      setStatus('paused');
    } catch (err) {
      console.warn('æš‚åœå¤±è´¥:', err);
    }
  };

  const handleResume = () => {
    if (!recorderRef.current) return;
    try {
      recorderRef.current.resumeRecording();
      setStatus('recording');
    } catch (err) {
      console.warn('ç»§ç»­å¤±è´¥:', err);
    }
  };

  const handleClear = () => {
    if (onTextChange) onTextChange(''); // æ¸…ç©ºçˆ¶ç»„ä»¶æ–‡æœ¬
    setMediaBlobUrl('');
    setSeconds(0);
  };

  return (
    <div style={{ border: '1px solid #ddd', padding: '1rem', borderRadius: '6px', background: '#f9f9f9' }}>
      <h3>è¯­éŸ³è¾“å…¥</h3>

      {/* è½¬å½•æ–¹å¼é€‰æ‹©å™¨ */}
      <div style={{ display: 'flex', gap: 8, marginBottom: 8, alignItems: 'center', flexWrap: 'wrap' }}>
        <span style={{ fontSize: '0.95rem', color: '#333' }}>è½¬å½•æ–¹å¼ï¼š</span>
        <button
          onClick={() => { setTranscriptionMethod('whisper'); if (typeof window !== 'undefined') localStorage.setItem('transcriptionMethod', 'whisper'); setFailureCount(0); }}
          disabled={isUploading || status !== 'idle'}
          style={{ background: transcriptionMethod === 'whisper' ? '#2563eb' : '#e5e7eb', color: transcriptionMethod === 'whisper' ? '#fff' : '#111', border: 'none', borderRadius: 4, padding: '6px 10px' }}
        >
          ğŸ–¥ï¸ æœ¬åœ° Whisper
        </button>
        <button
          onClick={() => { setTranscriptionMethod('baidu'); if (typeof window !== 'undefined') localStorage.setItem('transcriptionMethod', 'baidu'); setFailureCount(0); }}
          disabled={isUploading || status !== 'idle'}
          style={{ background: transcriptionMethod === 'baidu' ? '#2563eb' : '#e5e7eb', color: transcriptionMethod === 'baidu' ? '#fff' : '#111', border: 'none', borderRadius: 4, padding: '6px 10px' }}
        >
          â˜ï¸ ç™¾åº¦ API
        </button>
        {transcriptionMethod === 'whisper' && failureCount > 0 && (
          <span style={{ color: '#d97706', marginLeft: 8 }}>âš ï¸ æœ¬åœ° Whisper å·²å¤±è´¥ {failureCount} æ¬¡ï¼Œè¿ç»­å¤±è´¥ 3 æ¬¡å°†è‡ªåŠ¨åˆ‡æ¢è‡³ç™¾åº¦ API</span>
        )}
      </div>

      {/* å½•éŸ³æ§åˆ¶åŒº */}
      <div style={{ display: 'flex', gap: 8, marginBottom: 12, alignItems: 'center', flexWrap: 'wrap' }}>
        <button onClick={handleStart} disabled={status === 'recording'}>
          å¼€å§‹å½•éŸ³
        </button>
        <button onClick={handleStop} disabled={status !== 'recording' && status !== 'paused'}>
          åœæ­¢å½•éŸ³
        </button>
        <button onClick={handlePause} disabled={status !== 'recording'}>
          æš‚åœ
        </button>
        <button onClick={handleResume} disabled={status !== 'paused'}>
          ç»§ç»­
        </button>
        <span style={{ color: '#555' }}>
          è®¡æ—¶ï¼š{String(Math.floor(seconds / 60)).padStart(2, '0')}:{String(seconds % 60).padStart(2, '0')}
        </span>

        {/* ä½¿ç”¨æ–°çš„éŸ³é‡å¯è§†åŒ–ç»„ä»¶ */}
        <VolumeVisualizer volume={volume} status={status} />
      </div>

      {mediaBlobUrl && (
        <div style={{ marginBottom: 12 }}>
          <label>å½•éŸ³å›æ”¾ï¼š</label>
          <audio src={mediaBlobUrl} controls style={{ width: '100%' }} />
        </div>
      )}

      <div style={{ marginBottom: 12 }}>
        <label style={{ display: 'block', marginBottom: '6px', fontWeight: '600', color: '#374151' }}>
          ğŸ“ è½¬å½•æ–‡æœ¬ï¼ˆå¯ç¼–è¾‘ï¼‰ï¼š
        </label>
        {isUploading && (
          <p style={{ color: '#666', fontSize: '0.9rem', margin: '8px 0' }}>
            {transcriptionMethod === 'whisper' ? 'ğŸ–¥ï¸ ä½¿ç”¨æœ¬åœ° Whisper è½¬å½•ä¸­...' : 'â˜ï¸ ä½¿ç”¨ç™¾åº¦ API è½¬å½•ä¸­...'}
          </p>
        )}
        <textarea
          value={transcribedText || ''}
          onChange={(e) => onTextChange && onTextChange(e.target.value)}
          style={{ 
            width: '100%', 
            height: '140px', 
            padding: '12px', 
            fontFamily: 'inherit', 
            fontSize: '1rem',
            lineHeight: '1.6',
            border: '2px solid #d1d5db', 
            borderRadius: '8px',
            resize: 'vertical',
            transition: 'border-color 0.2s',
            outline: 'none'
          }}
          onFocus={(e) => e.target.style.borderColor = '#3b82f6'}
          onBlur={(e) => e.target.style.borderColor = '#d1d5db'}
          placeholder="è½¬å½•ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œï¼Œä½ å¯ä»¥éšæ—¶ç¼–è¾‘ä¿®æ­£..."
        />
        {transcribedText && !isUploading && (
          <p style={{ fontSize: '0.85rem', color: '#6b7280', marginTop: '6px', marginBottom: 0 }}>
            âœ¨ æç¤ºï¼šè¯·æ£€æŸ¥å¹¶ä¿®æ­£è½¬å½•é”™è¯¯ï¼Œç„¶åç‚¹å‡»ã€Œæäº¤ AI è¯„ä¼°ã€
          </p>
        )}
      </div>

      <button onClick={handleClear} style={{ background: '#999', color: '#fff', border: 'none', borderRadius: '4px', padding: '6px 12px', cursor: 'pointer' }}>
        æ¸…ç©ºå½•éŸ³
      </button>
    </div>
  );
}

export default VoiceRecorder;
